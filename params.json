{"name":"Fussy","tagline":"A recommendation engine that care about user actions","body":"node-fussy\r\n==========\r\n\r\n*javascript recommendation engine*\r\n\r\nNOTE: I'm not an English native, so feel free to open issues if you see typos and bad grammar\r\n\r\n## Usage\r\n\r\n### Installation\r\n\r\n    $ npm install https://github.com/jbilcke/node-fussy --save\r\n\r\n### Basic demo\r\n\r\n```Javascript\r\nvar fussy = require('fussy');\r\nvar events = [\r\n  {\r\n    user: 'test_user', // a unique ID to identify a user\r\n    content: \"a video advertisement about an upcoming movie featuring pirates\",\r\n    signal: fussy.POSITIVE\r\n  }, {\r\n    user: 'test_user',\r\n    content: \"a youtube ad about hackers\",\r\n    signal: fussy.POSITIVE\r\n  }, {\r\n    user: 'test_user',\r\n    content: \"a facebook ad selling cloud hosting\",\r\n    signal: fussy.POSITIVE\r\n  }, {\r\n    user: 'test_user',\r\n    content: \"a video advertisement featuring video games\",\r\n    signal: fussy.NEGATIVE\r\n  }, {\r\n    user: 'test_user',\r\n    content: \"a facebook ad about video games\",\r\n    signal: fussy.NEGATIVE\r\n  }\r\n];\r\n\r\n\r\nvar engine = new fussy.Engine(\"./existing_database.json\");\r\n// OR\r\nvar engine = new fussy.Engine({\r\n  \"ngramSize\": 3,\r\n  \"debug\": true // totally optional, if you enable this this will print some stuff to the console\r\n});\r\n\r\nfor (var i=0 ; i < events.length ; i++) {\r\n  engine.pushEvent(events[i]);\r\n}\r\n\r\n// just for debug\r\nconsole.log(JSON.stringify(engine.profiles));\r\n\r\n// exports the database to a json file\r\nengine.saveAs(\"demo1.json\");\r\n```\r\n\r\n## Algorithm\r\n\r\n1. The user evaluates an object (eg. a tweet, a song, an ad..) by giving a score.\r\nThis score is typically +1 for a positive evaluation (eg. a like, a click on an ad, or when he buys a product),\r\nbut it can also be -1, for negative evaluation (eg. dislike, product removed from the cart, ad marked as irrelevant)\r\n\r\n2. This score is sent together with a content to the recommendation engine. For the moment the content *must* be a plain english text string (this can be a wikipedia page, an ontology, a list of keywords.. anything relevant, with some meaning).\r\n\r\n3. The engine extracts patterns of concepts (n-grams), and will reinforce (or weaken) connections between these concepts, depending on the evaluation given by the user.\r\n\r\n4. The engine also try to detect weak relationships between concepts, by injecting synonyms from a thesaurus of the English language. It is nice because it can create hidden links between objects very quickly (eg. \"dog picture\" will be weakly connected to \"wolf video\", even if we never display a \"dog video\" or a \"wolf picture\" to the user)\r\n\r\n\r\n## Features\r\n\r\n### Efficient\r\n\r\nEven if data is scarce, the injection of external relationships make it possible to work on a few events (eg. less than 10). It won't be perfect, but it should still perform better than with no data at all.\r\n\r\n### Self-regulating\r\n\r\nThe network can change over time. New connections can be created, old ones can be reinforced or deleted. A user can choose to hate something he used to love months ago.\r\n\r\n### More or less customizable\r\n\r\nYou are not limited to -1 or +1, you can use any value. For instance if the user likes a product, that could be a +1, and if he buys it, a +5. This is up to you, you should do AB testing or other research to tweak this.\r\nJust remember that a signal value of 0 will have no effect, because it represents the non-action (eg. the user just ignore the ad, or skip a product evaluation). If you want to force a link to be weakened (eg. automatically, after a few days or weeks) you have to use a negative value.\r\n\r\n## Known issues\r\n\r\n * It would work better with a filter for the most common (and thus irrelevant) keywords. Than can be implemented using some kind of TF-IDF-like algorithm, but I've just not done it yet.\r\n\r\n * Injecting additional, weak connections is powerful, but using a thesaurus is still a bit limited. It would work even better with network data from DBpedia's ontology, or other semantic graph databases.\r\n\r\n * The memory usage can be a problem, because a lot of data is stored per-user. You will eventually need to purge the network from time to time, in order to remove the weakest/old links. That could be automatic, but it depends on how much memory you can use, so it won't be easy to implement this kind of GC.\r\n\r\n * The profile networks are not easily human-readable. They are made by and for the machine. But you could try to export them to visualize the graph in Gephi for instance.\r\n\r\n\r\n## TODO\r\n\r\n * Export / Save of the recommendation database. That's a block, without that Iit is still a bit useless.\r\n\r\n\r\n## Changelog\r\n\r\n#### 0.0.2\r\n\r\n * Total rewrite. See README for more information. Yup, this file.\r\n\r\n#### 0.0.1 (Wednesday, December 5, 2012)\r\n\r\n * Added `database.size`\r\n * Added `database.prune(threshold)`\r\n * Added `database.toFile(fileName)`\r\n * Removed the toy Twitter database from core\r\n * Added an example crawler you could use to build a tag database\r\n\r\n#### 0.0.0\r\n\r\n * Initial version, not very documented\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}